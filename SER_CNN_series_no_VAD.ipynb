{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMq+GG6eAUPyz3wsrTVwvg4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "7EKZJ8kv7Vlo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive"
      ],
      "metadata": {
        "id": "ofZWYswc9Pzy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAd61PWI6zjd",
        "outputId": "f457c961-11dc-4f45-e564-cf2cfce5abfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies"
      ],
      "metadata": {
        "id": "xwTfbD8r9TAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 -q install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 torchtext==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryUkO1AG63x0",
        "outputId": "4b2bc38f-8ccd-46e9-92b4-1b1045a3db05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |█████████████                   | 834.1 MB 14.9 MB/s eta 0:01:22tcmalloc: large alloc 1147494400 bytes == 0x3a8ae000 @  0x7f412c5f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 1.2 MB/s eta 0:13:41tcmalloc: large alloc 1434370048 bytes == 0x7ef04000 @  0x7f412c5f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 1.5 MB/s eta 0:07:44tcmalloc: large alloc 1792966656 bytes == 0x3d36000 @  0x7f412c5f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.2 MB/s eta 0:04:47tcmalloc: large alloc 2241208320 bytes == 0x6eb1e000 @  0x7f412c5f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 90.9 MB/s eta 0:00:01tcmalloc: large alloc 2041315328 bytes == 0xf4480000 @  0x7f412c5f81e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
            "tcmalloc: large alloc 2551644160 bytes == 0x1e23f8000 @  0x7f412c5f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 8.6 kB/s \n",
            "\u001b[K     |████████████████████████████████| 20.6 MB 1.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 25.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchsummary==1.5.1"
      ],
      "metadata": {
        "id": "HRBCW3YiBTvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -qq install librosa\n",
        "!pip -qq install sklearn"
      ],
      "metadata": {
        "id": "OgkNb_oWXVxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torchsummary"
      ],
      "metadata": {
        "id": "aXBf1fBpVfPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0oJ0nJQ684v",
        "outputId": "0ff4633d-8e7e-47bc-b52a-1f836649042f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n",
            "11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cudnn.enabled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNKX82097BiX",
        "outputId": "3e187c28-dff5-4ae2-bfcc-0e866de923d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sVBTM5Q6-cb",
        "outputId": "ba0867ed-7b89-4c3f-9b41-00de73eb807c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torchaudio"
      ],
      "metadata": {
        "id": "dEwX6ir5ekmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Device"
      ],
      "metadata": {
        "id": "Q5KGAt-n9Y0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = \"cuda\"\n",
        "else:\n",
        "  device = \"cpu\"\n",
        "print(f\"Using {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdoqhXcW9Iqp",
        "outputId": "dae481f1-30f4-4381-8b2f-3934db61adf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "O7slktvS7Q3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customization"
      ],
      "metadata": {
        "id": "9PC5pCyO8nR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "\n",
        "  def __init__(self,\n",
        "        annotations_file,\n",
        "        audio_dir,\n",
        "        transformation,\n",
        "        target_sample_rate,\n",
        "        num_samples,\n",
        "        device):\n",
        "    '''\n",
        "    Arguments:\n",
        "      annotations: path to csv file\n",
        "      audio_dir: path to audio dir\n",
        "      transformation: any audio tranform (Mel-spec, MFCC etc) provided by torch audio\n",
        "               (function pointer in fact, callable)\n",
        "      target_sample_rate: as named\n",
        "    '''\n",
        "    Dataset.__init__(self)\n",
        "    self.annotations = pd.read_csv(annotations_file)\n",
        "    print(self.annotations)\n",
        "    self.audio_dir = audio_dir\n",
        "    self.device = device\n",
        "    # print(self.device)\n",
        "    self.transformation = transformation.to(self.device)\n",
        "    self.target_sample_rate = target_sample_rate\n",
        "    self.num_samples = num_samples\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    '''\n",
        "    loading the waveform sample specified by the index\n",
        "    \n",
        "    Returns:\n",
        "      signal: <transformed> waveform\n",
        "      label: text in this case\n",
        "    '''\n",
        "    audio_sample_path = self._get_audio_sample_path(index)\n",
        "    label = self._get_audio_sample_label(index)\n",
        "\n",
        "    signal, sr = torchaudio.load(audio_sample_path)\n",
        "    signal = signal.to(self.device)\n",
        "    # signal = signal.cuda()\n",
        "    # Note: signal has shape (num_channels, num_samples) -> (2, 16000) -> (1, 16000)\n",
        "\n",
        "    signal = self._resample_if_necessary(signal, sr)  # resampling\n",
        "    signal = self._mix_down_if_necessary(signal)    # reduce to mono-channel (aggregate over 0st dim)\n",
        "    signal = self._cut_if_necessary(signal)\n",
        "    signal = self._right_pad_if_necessary(signal)   # right padding (when have less than expected)\n",
        "    signal = self.transformation(signal)       # apply tranformation\n",
        "\n",
        "    return signal, label\n",
        "\n",
        "  def _get_audio_sample_path(self, index):\n",
        "    '''\n",
        "    Join <dir name> & <.wav filename in df anno>\n",
        "    retrieve complete index-th audio sample url\n",
        "\n",
        "    Returns:\n",
        "      path: complete i-th audio sample url\n",
        "    '''\n",
        "\n",
        "    file_name = f'{self.annotations.iloc[index, 0]}.wav' # 0st col: 'UID'\n",
        "    path = os.path.join(self.audio_dir, file_name)\n",
        "    return path\n",
        "    \n",
        "  def _get_audio_sample_label(self, index):\n",
        "    # return self.annotations.iloc[index, 3] # 1st col: 'UTT' 4th: 'EMOTION'\n",
        "\n",
        "    label1 = self.annotations.iloc[index, 3]\n",
        "    # label2 = torch.from_numpy(self.annotations.iloc[index, 4:7].to_numpy().astype(np.float32))\n",
        "\n",
        "    # return {'label1': label1, 'label2': label2}\n",
        "    return {'label1': label1}\n",
        "\n",
        "  def _cut_if_necessary(self, signal):\n",
        "    if signal.shape[1] > self.num_samples:\n",
        "      signal = signal[:, :self.num_samples]\n",
        "    return signal\n",
        "\n",
        "  def _right_pad_if_necessary(self, signal):\n",
        "    length_signal = signal.shape[1]\n",
        "    if length_signal < self.num_samples:\n",
        "      num_missing_samples = self.num_samples - length_signal\n",
        "      last_dim_padding = (0, num_missing_samples) #(1, 2) 1 left 2 right\n",
        "      # [1, 1, 1] -> [0, 1, 1, 1, 0, 0]\n",
        "      signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
        "    return signal\n",
        "\n",
        "  def _resample_if_necessary(self, signal, sr):\n",
        "    if sr != self.target_sample_rate:\n",
        "      if self.device == \"cpu\":\n",
        "        resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
        "      elif self.device == 'cuda':\n",
        "        resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate).cuda()\n",
        "      else:\n",
        "        raise Exception(\"Device type error!\")\n",
        "      signal = resampler(signal)\n",
        "    return signal\n",
        "\n",
        "  def _mix_down_if_necessary(self, signal):\n",
        "    if signal.shape[0] > 1: # i.e. (2, 1000)\n",
        "      signal = torch.mean(signal, dim=0, keepdim=True)\n",
        "    return signal"
      ],
      "metadata": {
        "id": "_Bn0QIQJc3p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instantiation\n",
        "\n",
        "- Dataset\n",
        "- Data loader"
      ],
      "metadata": {
        "id": "Y1zoomhb8Sh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ANNOTATIONS_FILE = \"/content/drive/MyDrive/Dissertation/Datasets/cleaned_1.0/better_train_less.csv\"\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/Dissertation/Speech\"\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "# BATCH_SIZE = 32\n",
        "\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# SAMPLE_RATE = 16000\n",
        "# NUM_SAMPLES = 220500 * 3\n",
        "\n",
        "SAMPLE_RATE = 8000\n",
        "NUM_SAMPLES = 8000 * 2\n",
        "# NUM_SAMPLES = 16000 * 3"
      ],
      "metadata": {
        "id": "Ua2LdQVbduzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def create_data_loader(train_data, batch_size):\n",
        "  train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
        "  return train_dataloader\n",
        "\n",
        "# instantiating our dataset object and create data loader\n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "  sample_rate=SAMPLE_RATE,\n",
        "  n_fft=1024,\n",
        "  hop_length=512,\n",
        "  n_mels=64\n",
        ")\n",
        "\n",
        "iemocap = AudioDataset(\n",
        "      ANNOTATIONS_FILE,\n",
        "      AUDIO_DIR,\n",
        "      mel_spectrogram,\n",
        "      SAMPLE_RATE,\n",
        "      NUM_SAMPLES,\n",
        "      device\n",
        "      )\n",
        "\n",
        "train_dataloader = create_data_loader(iemocap, BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrA5C4mY8Tka",
        "outputId": "f36c5752-25de-464a-ccfc-675a62dbf0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         UID  \\\n",
            "0        Ses03M_impro04_M041   \n",
            "1        Ses01M_impro06_M011   \n",
            "2        Ses02M_impro08_M018   \n",
            "3        Ses03M_impro03_M011   \n",
            "4        Ses05F_impro03_F040   \n",
            "...                      ...   \n",
            "3125     Ses05M_impro01_F021   \n",
            "3126  Ses04F_script03_2_F030   \n",
            "3127     Ses05M_impro08_M024   \n",
            "3128  Ses03M_script01_2_M004   \n",
            "3129     Ses05F_impro06_F005   \n",
            "\n",
            "                                                    UTT EMOTIONS  EMOTION  \\\n",
            "0     Like, wow you're really smart we're going to g...        3        3   \n",
            "1     No, I mean it just came on really quick, you k...        2        2   \n",
            "2                                                 Okay.        0        0   \n",
            "3     Ah...Anyways, so she took the ring and she goe...        3        3   \n",
            "4                          There's still time for that.        3        3   \n",
            "...                                                 ...      ...      ...   \n",
            "3125  I'm gonna- I'm gonna bring security over and h...        1        1   \n",
            "3126                                               Why?        1        1   \n",
            "3127   Absolutely.  It's a new service we are offering.        0        0   \n",
            "3128               Who said he even thought about that?        0        0   \n",
            "3129                                           Kind of.        2        2   \n",
            "\n",
            "             V         A         D  neu  ang  sad  hap  neu_m  ang_m  sad_m  \\\n",
            "0     0.777778  0.625000  0.333333    0    0    0    1      0      0      0   \n",
            "1     0.222222  0.375000  0.555556    0    0    1    0      0      0      1   \n",
            "2     0.444444  0.333325  0.407400    1    0    0    0      1      0      0   \n",
            "3     0.666667  0.750000  0.777778    0    0    0    1      0      0      0   \n",
            "4     0.666667  0.625000  0.555556    0    0    0    1      0      0      0   \n",
            "...        ...       ...       ...  ...  ...  ...  ...    ...    ...    ...   \n",
            "3125  0.111111  0.750000  0.888889    0    1    0    0      0      1      0   \n",
            "3126  0.333333  0.375000  0.555556    0    1    0    0      0      1      0   \n",
            "3127  0.555556  0.625000  0.555556    1    0    0    0      1      0      0   \n",
            "3128  0.333333  0.500000  0.555556    1    0    0    0      1      0      0   \n",
            "3129  0.111111  0.375000  0.444444    0    0    1    0      0      0      1   \n",
            "\n",
            "      hap_m  \n",
            "0         1  \n",
            "1         0  \n",
            "2         0  \n",
            "3         1  \n",
            "4         1  \n",
            "...     ...  \n",
            "3125      0  \n",
            "3126      0  \n",
            "3127      0  \n",
            "3128      0  \n",
            "3129      0  \n",
            "\n",
            "[3130 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import IPython.display as ipd\n",
        "\n",
        "# print(f'<{len(iemocap)}> samples confirmed in the dataset.')\n",
        "\n",
        "# print(iemocap[1])\n",
        "\n",
        "# sample_signal, sample_label = iemocap[1]\n",
        "\n",
        "# print(f'Sample Audio: {sample_signal.shape}')\n",
        "# print(f'Sample Label: {sample_label}')\n",
        "\n",
        "\n",
        "# # ipd.Audio(data=np.asarray(iemocap[1][0]), autoplay=True, rate=16000)\n",
        "# ipd.Audio(data=np.asarray(sample_signal), autoplay=True, rate=16000)"
      ],
      "metadata": {
        "id": "DfjjZ5bEdxy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Split"
      ],
      "metadata": {
        "id": "3LBd_4IucbRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(40).reshape(1,1,5,8)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEDOliYEcaxK",
        "outputId": "0e78c294-37b4-4cbd-c5c6-fdbf0878f883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
              "          [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
              "          [16, 17, 18, 19, 20, 21, 22, 23],\n",
              "          [24, 25, 26, 27, 28, 29, 30, 31],\n",
              "          [32, 33, 34, 35, 36, 37, 38, 39]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsxxLeqXeWAQ",
        "outputId": "911b48ac-998b-4a6b-953b-76100f25ba59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def slicing(tensor, r=4):\n",
        "  len_time = a.shape[-1]\n",
        "  assert len_time % r == 0, f'not dividable by r of {r}'\n",
        "  len_small = len_time // r\n",
        "  return [\n",
        "      a[:,:,:, i:i+2] for i in range(0, len_time, len_small)\n",
        "  ]"
      ],
      "metadata": {
        "id": "07ChRpCieQrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "slicing(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvM6YWCchHCI",
        "outputId": "06e6a478-425f-4c94-aca0-c8f3bb2ada6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[[ 0,  1],\n",
              "           [ 8,  9],\n",
              "           [16, 17],\n",
              "           [24, 25],\n",
              "           [32, 33]]]]), tensor([[[[ 2,  3],\n",
              "           [10, 11],\n",
              "           [18, 19],\n",
              "           [26, 27],\n",
              "           [34, 35]]]]), tensor([[[[ 4,  5],\n",
              "           [12, 13],\n",
              "           [20, 21],\n",
              "           [28, 29],\n",
              "           [36, 37]]]]), tensor([[[[ 6,  7],\n",
              "           [14, 15],\n",
              "           [22, 23],\n",
              "           [30, 31],\n",
              "           [38, 39]]]])]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(slicing(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUqkXl4fgKu7",
        "outputId": "90227827-63e7-40a2-ed6d-c5846a0b9542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(slicing(a), -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1sD8hgbeCC7",
        "outputId": "66000fe0-f24c-4055-b773-59ecaf4b6213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
              "          [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
              "          [16, 17, 18, 19, 20, 21, 22, 23],\n",
              "          [24, 25, 26, 27, 28, 29, 30, 31],\n",
              "          [32, 33, 34, 35, 36, 37, 38, 39]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture"
      ],
      "metadata": {
        "id": "YBScDngq7fYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "gqZP3cml7Qeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `__init__()`: the constructor defining layer structure of the network.\n",
        "\n",
        "- `forward()`: instruct pytorch how to pass the information/data from one layer to next."
      ],
      "metadata": {
        "id": "C0hq8zuh74SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "iLj1GkIMxNMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNNetwork(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # sequential convolutions  / flatten / linear / softmax\n",
        "    self.convSeq = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=16,  # 16 filters\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=2\n",
        "        ),\n",
        "        nn.Tanh(),\n",
        "        # nn.Dropout2d(0.1),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Conv2d(\n",
        "            in_channels=16,\n",
        "            out_channels=32,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=2\n",
        "        ),\n",
        "        nn.Tanh(),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Conv2d(\n",
        "            in_channels=32,\n",
        "            out_channels=64,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=2\n",
        "        ),\n",
        "        nn.Tanh(),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Conv2d(\n",
        "            in_channels=64,\n",
        "            out_channels=128,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=2\n",
        "        ),\n",
        "        nn.Tanh(),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Flatten()\n",
        "\n",
        "    )\n",
        "\n",
        "    # flatten\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    # linear/dense\n",
        "    # self.linear = nn.Linear(128 * 5 * 4, 4)\n",
        "    self.linear1 = nn.Sequential(\n",
        "        # nn.Linear(128 * 1 * 8, 800),\n",
        "        nn.Linear(64 * 5 * 4, 400),\n",
        "        nn.Tanh(),\n",
        "        # nn.Linear(54000, 4000),\n",
        "        # nn.Tanh(),\n",
        "        # nn.BatchNorm1d(1024),\n",
        "        nn.Linear(400, 4)\n",
        "    )\n",
        "\n",
        "    # # VAD\n",
        "    # self.linear2 = nn.Sequential(\n",
        "    #     nn.Linear(64 * 5 * 4, 512),\n",
        "    #     nn.Tanh(),\n",
        "    #     nn.Linear(512, 300),\n",
        "    #     nn.Tanh(),\n",
        "    #     # nn.BatchNorm1d(1024),\n",
        "    #     nn.Linear(300, 3)\n",
        "    # )\n",
        "\n",
        "    # softmax\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "  \n",
        "  # how to pass data through layers\n",
        "  def forward(self, input_data):\n",
        "\n",
        "    one = input_data[:,:,:, 0:input_data.shape[-1] // 4]\n",
        "    two = input_data[:,:,:, input_data.shape[-1] // 4: input_data.shape[-1] // 4 * 2]\n",
        "    thr = input_data[:,:,:, input_data.shape[-1] // 4 * 2:input_data.shape[-1] // 4 * 3]\n",
        "    fou = input_data[:,:,:, input_data.shape[-1] // 4 * 3:input_data.shape[-1] // 4 * 4]\n",
        "\n",
        "    one = self.convSeq(one)\n",
        "    two = self.convSeq(two)\n",
        "    thr = self.convSeq(thr)\n",
        "    fou = self.convSeq(fou)\n",
        "\n",
        "    # x = torch.cat((one,two,thr,fou), -1)\n",
        "    # x = torch.cat((one,two,thr,fou), 0)\n",
        "\n",
        "    x = torch.add(one, two)\n",
        "    x = torch.add(x, thr)\n",
        "    x = torch.add(x, fou)\n",
        "    # x = one+two+thr+fou\n",
        "    x = x * 0.25\n",
        "\n",
        "    # x = F.pad(x, pad=(0, 0, 0, 1920 - x.shape[0]))\n",
        "    # print(x.shape)\n",
        "    x.to(device)\n",
        "\n",
        "    x1 = self.linear1(x)\n",
        "    # x2 = self.linear2(x)\n",
        "\n",
        "    x1 = self.softmax(x1)\n",
        "    # return x1, x2\n",
        "    return x1"
      ],
      "metadata": {
        "id": "aFbqKRL17cxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn_sample = CNNNetwork()\n",
        "# summary(\n",
        "#     cnn.cuda(),  # model\n",
        "    \n",
        "#      # shape of the spetrogram\n",
        "#     (\n",
        "#         1,  # number of channels\n",
        "#         64,  # number of mel-banks\n",
        "#         44  # time axis\n",
        "#     )\n",
        "#     )"
      ],
      "metadata": {
        "id": "33T-KGv4BldX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "J6prNqqsawNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train & Save"
      ],
      "metadata": {
        "id": "N4s2bRL41OAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "# BATCH_SIZE = 128\n",
        "# EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# SAMPLE_RATE = 16000\n",
        "# NUM_SAMPLES = 22050\n",
        "\n",
        "\n",
        "def train_single_epoch(model, data_loader, loss_fn, optimiser, device, i):\n",
        "  for input, target in data_loader:\n",
        "    # input, target1, target2 = input.to(device), target['label1'].to(device), target['label2'].to(device)\n",
        "    input, target1 = input.to(device), target['label1'].to(device)\n",
        "\n",
        "    # calculate loss\n",
        "    out1 = model(input)\n",
        "    loss1 = loss_fn(out1, target1)\n",
        "    # out1, out2 = model(input)\n",
        "    # loss2 = nn.L1Loss()(out2, target2)\n",
        "\n",
        "    # backpropagate error and update weights\n",
        "    # loss = loss1 + loss2\n",
        "    loss = loss1\n",
        "    # writer.add_scalar(\"Loss/train\", loss, i)\n",
        "    optimiser.zero_grad()\n",
        "    \n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "  print(f\"loss: {loss.item()}\")\n",
        "\n",
        "\n",
        "def train(model, data_loader, loss_fn, optimiser, device, epochs):\n",
        "  for i in range(epochs):\n",
        "      print(f\"Epoch {i+1}\")\n",
        "      train_single_epoch(model, data_loader, loss_fn, optimiser, device, i)\n",
        "      print(\"---------------------------\")\n",
        "  print(\"Finished training\")"
      ],
      "metadata": {
        "id": "PJRrx_LPawUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss & Optimizer"
      ],
      "metadata": {
        "id": "meYOtBswN71g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construct model and assign it to device\n",
        "cnn = CNNNetwork().to(device)\n",
        "print(cnn)\n",
        "\n",
        "# initialise loss funtion + optimiser\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(\n",
        "                cnn.parameters(),\n",
        "                lr=LEARNING_RATE\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8IuuoeEbxGL",
        "outputId": "015f76b7-48a6-461a-e48a-b0ad5cf07d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNNNetwork(\n",
            "  (convSeq): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Tanh()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (4): Tanh()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (7): Tanh()\n",
            "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (10): Tanh()\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear1): Sequential(\n",
            "    (0): Linear(in_features=1280, out_features=400, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=400, out_features=4, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "train(cnn, train_dataloader, loss_fn, optimiser, device, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqJ0JdbNN31s",
        "outputId": "5c0d6a7c-ef63-4177-88ed-746437567369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "loss: 1.2133526802062988\n",
            "---------------------------\n",
            "Epoch 2\n",
            "loss: 1.1466076374053955\n",
            "---------------------------\n",
            "Epoch 3\n",
            "loss: 1.1346944570541382\n",
            "---------------------------\n",
            "Epoch 4\n",
            "loss: 1.1251883506774902\n",
            "---------------------------\n",
            "Epoch 5\n",
            "loss: 1.1225779056549072\n",
            "---------------------------\n",
            "Epoch 6\n",
            "loss: 1.1245322227478027\n",
            "---------------------------\n",
            "Epoch 7\n",
            "loss: 1.130554437637329\n",
            "---------------------------\n",
            "Epoch 8\n",
            "loss: 1.135025143623352\n",
            "---------------------------\n",
            "Epoch 9\n",
            "loss: 1.0455280542373657\n",
            "---------------------------\n",
            "Epoch 10\n",
            "loss: 1.0457149744033813\n",
            "---------------------------\n",
            "Finished training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# writer.flush()\n",
        "# writer.close()"
      ],
      "metadata": {
        "id": "gr2o7xw4yPGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !kill 2108"
      ],
      "metadata": {
        "id": "L4LusTiH4dk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorboard --logdir = content/logsdir\n",
        "# %tensorboard --logdir content/drive/MyDrive/Dissertation/Models/logsdirs/logsdir1/"
      ],
      "metadata": {
        "id": "LsEdZ10gu_nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving"
      ],
      "metadata": {
        "id": "q21AVsvFOCfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# output_path = \"/content/drive/MyDrive/Dissertation/Models/SER/clean_1.0/CNN_series.pth\"\n",
        "output_path = \"/content/drive/MyDrive/Dissertation/Models/SER/clean_1.0/CNN_series_no_vad_new.pth\""
      ],
      "metadata": {
        "id": "MQL5ehKwyjht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "torch.save(cnn.state_dict(), output_path)\n",
        "print(f\"Trained feed forward net saved at [{output_path}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGlEYj9pN2Xm",
        "outputId": "bc594ac7-d795-4622-a1fe-845d23cbe1d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained feed forward net saved at [/content/drive/MyDrive/Dissertation/Models/SER/clean_1.0/CNN_series_no_vad_new.pth]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "PGfNH9cbo76e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class Mapping"
      ],
      "metadata": {
        "id": "5Uo9zM6po_ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_mapping = ['neu','ang','sad','hap']\n",
        "INDICE = [0, 1, 2, 3]\n",
        "\n",
        "EMO_2_ID = dict(zip(class_mapping, INDICE))\n",
        "ID_2_EMO = dict(zip(INDICE, class_mapping))"
      ],
      "metadata": {
        "id": "e_-uRBYHo2wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions"
      ],
      "metadata": {
        "id": "TTa0Wt8spp-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, input, target, class_mapping):\n",
        "  model.eval()\n",
        "\n",
        "  # no need for gradient during inference\n",
        "  with torch.no_grad():\n",
        "    # predictions, vad = model(input)\n",
        "    # predictions, vads = model(input)\n",
        "    predictions = model(input)\n",
        "    # tensor (1, 4) -> [[0,1, 0.2, 0.6, 0.1]]\n",
        "\n",
        "    predicted_index = predictions[0].argmax(0)\n",
        "    # print(predicted_index)\n",
        "\n",
        "    predicted = class_mapping[predicted_index]\n",
        "    expected = class_mapping[target]\n",
        "  return predicted, expected"
      ],
      "metadata": {
        "id": "CYfTUhd9poMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load back"
      ],
      "metadata": {
        "id": "xLAsaaiFqQCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_trained = CNNNetwork()\n",
        "state_dict = torch.load(output_path)\n",
        "cnn_trained.load_state_dict(state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TZikDRPqQUZ",
        "outputId": "4df6c99e-dd91-45c3-e52c-5ef4635fb16c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ANNOTATIONS_FILE = \"/content/drive/MyDrive/Dissertation/Datasets/cleaned_1.0/better_valid_less.csv\"\n",
        "ANNOTATIONS_FILE = \"/content/drive/MyDrive/Dissertation/Datasets/cleaned_1.0/better_test_less.csv\"\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/Dissertation/Speech\"\n",
        "\n",
        "# instantiating our dataset object and create data loader\n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "  sample_rate=SAMPLE_RATE,\n",
        "  n_fft=1024,\n",
        "  hop_length=512,\n",
        "  n_mels=64\n",
        ")\n",
        "\n",
        "iemocap_valid = AudioDataset(\n",
        "      ANNOTATIONS_FILE,\n",
        "      AUDIO_DIR,\n",
        "      mel_spectrogram,\n",
        "      SAMPLE_RATE,\n",
        "      NUM_SAMPLES,\n",
        "      'cpu'\n",
        "      # device\n",
        "      )\n",
        "\n",
        "# valid_dataloader = create_data_loader(iemocap_valid, BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrMYbAh1rEWF",
        "outputId": "acc52176-b89a-4631-d979-199709730933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         UID  \\\n",
            "0        Ses04F_impro06_F005   \n",
            "1        Ses04F_impro03_M021   \n",
            "2     Ses04M_script02_2_F019   \n",
            "3        Ses03M_impro06_M020   \n",
            "4        Ses03F_impro04_F023   \n",
            "...                      ...   \n",
            "1039  Ses01F_script03_2_M020   \n",
            "1040  Ses03M_script03_2_M021   \n",
            "1041     Ses04M_impro07_M007   \n",
            "1042  Ses05M_script03_2_M030   \n",
            "1043  Ses01M_script01_3_F016   \n",
            "\n",
            "                                                    UTT EMOTIONS  EMOTION  \\\n",
            "0     He was only twenty four and just so many thing...        2        2   \n",
            "1                      I know but you just asked me to-        0        0   \n",
            "2     I'd rather not remember some things.  I'd rath...        2        2   \n",
            "3        and then something like this happens you know?        2        2   \n",
            "4                                Yeah, I guess I could.      0,2        2   \n",
            "...                                                 ...      ...      ...   \n",
            "1039  Oh really.  It's a pity you didn't have any br...    0,1,2        1   \n",
            "1040                                       I think that        0        0   \n",
            "1041  Yeah.  I like to know about history, 'cause, y...      0,3        3   \n",
            "1042  You know, we could get a really good debate go...        1        1   \n",
            "1043  I'll never forgive you for waiting so long.  A...        3        3   \n",
            "\n",
            "             V      A      D  neu  ang  sad  hap  neu_m  ang_m  sad_m  hap_m  \n",
            "0     0.111111  0.625  0.625    0    0    1    0      0      0      1      0  \n",
            "1     0.333333  0.750  0.750    1    0    0    0      1      0      0      0  \n",
            "2     0.222222  0.375  0.625    0    0    1    0      0      0      1      0  \n",
            "3     0.333333  0.125  0.625    0    0    1    0      0      0      1      0  \n",
            "4     0.333333  0.250  0.500    0    0    1    0      1      0      1      0  \n",
            "...        ...    ...    ...  ...  ...  ...  ...    ...    ...    ...    ...  \n",
            "1039  0.222222  0.750  0.875    0    1    0    0      1      1      1      0  \n",
            "1040  0.444444  0.375  0.375    1    0    0    0      1      0      0      0  \n",
            "1041  0.555556  0.750  0.750    0    0    0    1      1      0      0      1  \n",
            "1042  0.222222  1.000  0.875    0    1    0    0      0      1      0      0  \n",
            "1043  0.777778  0.500  0.375    0    0    0    1      0      0      0      1  \n",
            "\n",
            "[1044 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "P_bW4iaQt_f6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [batch_size, num_channels, freq, time]\n",
        "# input, target1, target2 = iemocap_valid[0][0], iemocap_valid[0][1]['label1'], iemocap_valid[0][1]['label2']\n",
        "input, target1 = iemocap_valid[0][0], iemocap_valid[0][1]['label1']\n",
        "\n",
        "# 0 is the index of insertion\n",
        "input.unsqueeze_(0)\n",
        "\n",
        "print(target1)\n",
        "\n",
        "# input, target1 = input.cuda(), torch.tensor(target1).cuda()\n",
        "\n",
        "predicted, expected = predict(cnn_trained, input, target1, class_mapping)\n",
        "\n",
        "print(f'Predicted: {predicted}, expected: {expected}')\n",
        "print(input.shape)\n",
        "print(len(iemocap_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOCbhJ3-scWI",
        "outputId": "4b46e7a0-32a0-4597-8883-888939500703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Predicted: sad, expected: sad\n",
            "torch.Size([1, 1, 64, 32])\n",
            "1044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def results(dataset, model):\n",
        "  predictions = []\n",
        "  expectations = []\n",
        "\n",
        "  size = len(dataset)\n",
        "  for i in range(size):\n",
        "    X, Y = dataset[i][0], dataset[i][1]['label1']\n",
        "    X.unsqueeze_(0)\n",
        "    # X = X.cuda()\n",
        "    # Y = torch.from_numpy(Y)\n",
        "    # Y = Y.cuda()\n",
        "    predicted, expected = predict(model, X, Y, class_mapping)\n",
        "    predictions.append(predicted)\n",
        "    expectations.append(expected)\n",
        "\n",
        "  return expectations, predictions\n",
        "\n",
        "y_true, y_predict = results(iemocap_valid, cnn_trained)"
      ],
      "metadata": {
        "id": "ma8ENIYy1w16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GM81I5N5yOu",
        "outputId": "c2d90d4e-8163-4b3a-b166-dd4dae79b64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1044"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ID_2_EMO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hsn3kZA8Bzq",
        "outputId": "645ef1c4-996c-4f57-eab4-7d6d306d7068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'neu', 1: 'ang', 2: 'sad', 3: 'hap'}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = [EMO_2_ID[y] for y in y_true]\n",
        "y_predict = [EMO_2_ID[y] for y in y_predict]"
      ],
      "metadata": {
        "id": "KM7hV-Um6166"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "c = classification_report(y_true, y_predict, target_names=class_mapping, zero_division=1)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZKg_SWu9iO6",
        "outputId": "d6fcc532-97c1-4d06-9a14-3e8b2021b27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neu       0.49      0.60      0.54       323\n",
            "         ang       0.58      0.66      0.62       219\n",
            "         sad       0.60      0.70      0.65       230\n",
            "         hap       0.43      0.20      0.27       272\n",
            "\n",
            "    accuracy                           0.53      1044\n",
            "   macro avg       0.52      0.54      0.52      1044\n",
            "weighted avg       0.52      0.53      0.51      1044\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UA = 0\n",
        "for i in range(len(y_true)):\n",
        "  if y_true[i] == y_predict[i]:\n",
        "    UA += 1\n",
        "UA /= len(y_true)\n",
        "UA\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-6bCq8A7bxr",
        "outputId": "ef84781d-0825-41de-ca6c-809233cb7d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5316091954022989"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_dict = classification_report(y_true, y_predict, target_names=class_mapping, zero_division=1, output_dict=True)\n",
        "c_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmTRKHfH9Kia",
        "outputId": "5cb878df-5259-4e72-ec3f-50215ab45746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neu': {'precision': 0.4911392405063291,\n",
              "  'recall': 0.6006191950464397,\n",
              "  'f1-score': 0.5403899721448469,\n",
              "  'support': 323},\n",
              " 'ang': {'precision': 0.5753968253968254,\n",
              "  'recall': 0.6621004566210046,\n",
              "  'f1-score': 0.6157112526539279,\n",
              "  'support': 219},\n",
              " 'sad': {'precision': 0.5955882352941176,\n",
              "  'recall': 0.7043478260869566,\n",
              "  'f1-score': 0.6454183266932271,\n",
              "  'support': 230},\n",
              " 'hap': {'precision': 0.432,\n",
              "  'recall': 0.19852941176470587,\n",
              "  'f1-score': 0.2720403022670025,\n",
              "  'support': 272},\n",
              " 'accuracy': 0.5316091954022989,\n",
              " 'macro avg': {'precision': 0.523531075299318,\n",
              "  'recall': 0.5413992223797767,\n",
              "  'f1-score': 0.5183899634397511,\n",
              "  'support': 1044},\n",
              " 'weighted avg': {'precision': 0.5164168329148431,\n",
              "  'recall': 0.5316091954022989,\n",
              "  'f1-score': 0.509413699894696,\n",
              "  'support': 1044}}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(ANNOTATIONS_FILE)\n",
        "names = df.columns.to_list()\n",
        "names[-4:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHij8GHBhzpf",
        "outputId": "17b7d188-0bf6-4618-b0b6-bd42e0bc5643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neu_m', 'ang_m', 'sad_m', 'hap_m']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_multi = df[['neu_m', 'ang_m', 'sad_m', 'hap_m']].to_numpy()\n",
        "y_true_multi.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF8ucfJSlKIG",
        "outputId": "7eca3cf0-e594-4366-92e4-8e0b73972634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1044, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_multi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTNBJqCZmE1x",
        "outputId": "3618f3a2-b06f-4dd0-f1ec-ae71f4bcf7cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, 1],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN64OiF4mIxY",
        "outputId": "42fec726-2065-497b-900c-1a9517a6353e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 1, 0, 2, 2, 1, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # y_predict_hot = pd.get_dummies(y_predict)\n",
        "y_predict = np.array(y_predict)\n",
        "# y_predict_hot = np.zeros(y_predict.size, y_predict.max() + 1)\n",
        "# y_predict_hot[np.arange(y_predict.size), y_predict] = 1\n",
        "# y_predict_hot"
      ],
      "metadata": {
        "id": "p2M-wZBwm7Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_predict"
      ],
      "metadata": {
        "id": "zVxEo1jUpXBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(n, class_num, col_wise=True):\n",
        "  a = np.eye(class_num)[n.reshape(-1)]\n",
        "  return a.T if col_wise else a"
      ],
      "metadata": {
        "id": "pW3X1BxopapI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_hot = one_hot(y_predict, 4, False)\n",
        "y_predict_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAMeC8bhpeap",
        "outputId": "5621cd44-7772-4ee5-a049-c1495b30a1bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c2 = classification_report(y_true_multi, y_predict_hot, target_names=class_mapping, zero_division=1)\n",
        "print(c2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7aZXnOdpxte",
        "outputId": "34f1909c-a606-4adc-cddd-06cd74178f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neu       0.60      0.52      0.56       454\n",
            "         ang       0.61      0.61      0.61       251\n",
            "         sad       0.66      0.67      0.67       269\n",
            "         hap       0.45      0.20      0.28       279\n",
            "\n",
            "   micro avg       0.60      0.50      0.54      1253\n",
            "   macro avg       0.58      0.50      0.53      1253\n",
            "weighted avg       0.58      0.50      0.53      1253\n",
            " samples avg       0.60      0.52      0.55      1253\n",
            "\n"
          ]
        }
      ]
    }
  ]
}